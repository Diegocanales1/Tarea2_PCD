{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07d6579",
   "metadata": {},
   "source": [
    "## ¿Qué es MLOps?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04b0d8",
   "metadata": {},
   "source": [
    "MLOps es el conjunto de procesos para llevar un modelo de Machine Learning a producción de forma que sea escalable, confiable y preciso.\n",
    "\n",
    "Lo necesitamos porque no basta con entrenar un modelo:\n",
    "\n",
    "- Los modelos usan mucha data que es difícil manejar.\n",
    "\n",
    "- Pequeños cambios en parámetros afectan mucho los resultados.\n",
    "\n",
    "- Hay que controlar las características (features) usadas.\n",
    "\n",
    "- Monitorear y depurar un modelo es más complejo que en software común.\n",
    "\n",
    "- Los datos del mundo real cambian, y el modelo debe adaptarse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985fab93",
   "metadata": {},
   "source": [
    "## DevOps vs MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a28f51c",
   "metadata": {},
   "source": [
    "DevOps se enfoca en desarrollar y desplegar aplicaciones de software (planear, programar, probar, lanzar y monitorear).\n",
    "\n",
    "MLOps es parecido, pero con pasos adicionales:\n",
    "\n",
    "- Scoping: definir el problema y verificar que necesite ML y tenga datos adecuados.\n",
    "\n",
    "- Data Engineering: recolectar, limpiar y organizar los datos.\n",
    "\n",
    "- Modeling: crear y entrenar el modelo, medir errores y rendimiento.\n",
    "\n",
    "- Deployment: empaquetar y desplegar el modelo (API, contenedor, nube, móvil, etc.).\n",
    "\n",
    "- Monitoring: vigilar la infraestructura y el desempeño del modelo, ajustarlo cuando cambien los datos o surja sesgo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be9ac7",
   "metadata": {},
   "source": [
    "## ML Production Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff61700a",
   "metadata": {},
   "source": [
    "Para poner un modelo de Machine Learning en producción se necesita mucho más que solo el código. Los principales componentes son:\n",
    "\n",
    "- Data Collection: reunir grandes cantidades de datos de diferentes fuentes.\n",
    "\n",
    "- Data Verification: comprobar que los datos sean válidos, actuales y bien estructurados.\n",
    "\n",
    "- Feature Extraction: elegir las variables (features) más importantes y descartar las irrelevantes.\n",
    "\n",
    "- Configuration: definir cómo se comunican los distintos sistemas (base de datos, endpoints, formato de inputs, etc.).\n",
    "\n",
    "- ML Code: desarrollar y mejorar el modelo con librerías como TensorFlow, PyTorch o scikit-learn.\n",
    "\n",
    "- Machine Resource Management: planear recursos de cómputo (CPU, GPU, memoria, almacenamiento y costos).\n",
    "\n",
    "- Analysis Tool: medir el rendimiento del modelo (pérdida, error, overfitting, drift).\n",
    "\n",
    "- Project Management Tool: organizar el proyecto y dar seguimiento al trabajo con datos y modelos.\n",
    "\n",
    "- Serving Infrastructure: desplegar el modelo en la nube (AWS, GCP, Azure) o en dispositivos/edge (apps móviles, chips especializados).\n",
    "\n",
    "- Monitoring: supervisar el modelo y la infraestructura con logs y herramientas de monitoreo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b21e96",
   "metadata": {},
   "source": [
    "## Ejemplo de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fc67c",
   "metadata": {},
   "source": [
    "Hay ejemplo para explicar cómo funciona el despliegue de un modelo de machine learning en producción. Habla de Jen, que tiene un enorme campo de calabazas y cada año le toca revisarlas una por una para ver cuáles sirven y cuáles no. Como eso es muy tardado, ella te pide ayuda para crear un motor de ML que pueda clasificar si una calabaza es buena o mala.\n",
    "\n",
    "Lo que haces primero es juntar fotos de calabazas de su campo, y también de la gente del pueblo que le compró. Obviamente algunos mandan fotos que no sirven (como sandías), pero con lo demás armas un dataset. Luego, junto con Jen, etiquetas las imágenes: cuáles son buenas, regulares o malas. Además revisas la calidad de las fotos, las pones en la misma resolución y ajustas contraste o brillo. Esa es la parte de preparación de datos.\n",
    "\n",
    "Después entrenas un modelo con TensorFlow, con una red neuronal convolucional, con capas de entrada, ocultas y de salida. Usas una parte de las imágenes para entrenar y otra para probar qué tan bien predice. Una vez que tienes resultados, comparas la precisión y si no es suficiente, ajustas los parámetros y vuelves a entrenar, hasta que quede con buena exactitud.\n",
    "\n",
    "Cuando ya funciona bien, lo despliegas: montas un servidor en la nube con APIs de predicción y hasta puedes hacerle una app o página donde Jen suba las fotos y reciba la respuesta al instante.\n",
    "\n",
    "La idea es que todo este proceso lo hiciste manualmente, paso por paso: recolectar datos, limpiar, entrenar, evaluar y desplegar. Y eso, en el mundo de MLOps, se conoce como Nivel 0: el modelo ya está en producción, pero sin automatizaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650a9d6",
   "metadata": {},
   "source": [
    "En el Nivel 1 de MLOps, lo que tenemos es una especie de autopiloto básico. Ya no estamos entrenando el modelo a mano todos los días. Armamos un pipeline que valida los datos, los prepara, entrena el modelo y hasta compara varias métricas para quedarse con el mejor. Tú solo te aseguras de que los datos estén bien y no estén desbalanceados. Con eso ya tienes un sistema que se maneja solito en tu compu o en un ambiente de desarrollo.\n",
    "\n",
    "El problema es que, aunque esto suena bien, no es suficiente si el modelo empieza a usarse en escenarios más grandes. Y ahí es donde surgen las preguntas:\n",
    "\n",
    "¿Mi modelo sigue funcionando si le meto nuevos tipos de datos (ejemplo: calabazas diferentes)?\n",
    "\n",
    "¿Se va a reentrenar automáticamente cuando entren datos frescos?\n",
    "\n",
    "¿Puede dar servicio a miles de usuarios al mismo tiempo?\n",
    "\n",
    "¿Cómo llevo un control de todas las versiones del modelo cuando lo despliego en distintas partes?\n",
    "\n",
    "Para resolver eso, llegamos al Nivel 2 de MLOps, que ya es un sistema mucho más organizado. Aquí metemos varias piezas nuevas:\n",
    "\n",
    "Primero, un Feature Store, que es como una despensa centralizada donde guardamos y transformamos los datos en features para usar. Así todo el pipeline sabe de dónde agarrar la información.\n",
    "\n",
    "Luego, un Metadata Store, que es básicamente un registro de todo lo que pasa en la tubería. Sirve para que cada etapa sepa qué se hizo antes y se pueda reproducir el proceso sin perderse.\n",
    "\n",
    "Después viene el Model Registry, que guarda todos los modelos entrenados junto con sus métricas. Imagina como una “colección de modelos” de donde eliges el mejor para mandar a producción.\n",
    "\n",
    "Ese modelo seleccionado entra a un CI/CD pipeline, que lo convierte en un Prediction Service. O sea un servicio al que se conectan los usuarios para hacer predicciones en tiempo real.\n",
    "\n",
    "Finalmente se agrega un monitoreo constante. Si de pronto el modelo empieza a fallar porque entraron datos muy distintos (ejemplo: nuevas calabazas genéticamente modificadas), se detecta la baja en rendimiento y se dispara un reentrenamiento automático.\n",
    "\n",
    "La idea es que este ciclo no se detenga: nuevos datos → modelo actualizado → servicio estable. Así el modelo se mantiene relevante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf3361",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
